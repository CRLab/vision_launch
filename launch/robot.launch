<launch>

	<arg name="robot"/>
	<arg name="image_topic"/>
	<arg name="camera_info_topic"/>
	
	<!-- Load robot, and checkerboard specific params onto the param server -->
	<rosparam command="load" file="$(find vision_launch)/configs/$(arg robot).yaml" />

	<!-- This detects the checkerboard in the scene -->
	<node pkg="checkerboard_detector" type="checkerboard_detector" name="checkerboard_detector" >
              <remap from="image" to="$(arg image_topic)" />
              <remap from="camera_info" to="$(arg camera_info_topic)" />
	</node>

	<!-- This publishes noisy observations of the checkerboard to the world_raw tf -->
	<node pkg="checkerboard_detector" type="objectdetection_tf_publisher.py" name="checkerboard_tf_publisher" >
		 <param name="use_simple_tf" value="true" />
	</node>

	<!-- These detecte the table in the pointcloud and uses it for a better world z estimate -->
	<!-- <node pkg="table_detector" type="table_detector" name="table_detector" /> -->
	<!-- <node pkg="filter_tf" type="filter_tf.py" name="filter_tf" />  -->

	<!-- uses both the observations of the checkerboard, and the known orientation of the robot base
	to produce the world tf, which also smoothed overtime -->
	<node pkg="filter_tf" type="filter_tf_base.py" name="filter_tf" />

	<!-- Uses the world frame to filter the pointcloud to only include objects overtop the table -->
	<include file="$(find pc_filter)/launch/pc_filter.launch">
	<arg name="robot" value="$(arg robot)" />
	</include>

</launch>
